<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">

    <title>Theory &middot; warrick.io</title>

    <link rel="stylesheet" href="//warrick.io/css/jane.css">
    <link rel="stylesheet" href="//warrick.io/css/syntax.css">
    <link rel="stylesheet" href="//warrick.io/css/font-awesome.css">


    <link href="//warrick.io/tags/theory/index.xml" rel="alternate" type="application/rss+xml" title="warrick.io" />
  </head>
  <body>
    
  <h1 class="brand">warrick.io</h1>

  <div class="links">
    <i class="fa-twitter-square"></i>
    <i class="fa-github-square"></i>
  </div>

  
    <article>
      <h2><a href="//warrick.io/posts/theory-highlights/">theory highlights</a></h2>
      <time>Feb 19, 2012</time>
      <blockquote>
<p>&ldquo;This discussion highlights an important difference between complexity theory
and computability theory. In computability theory, the Church-Turing thesis
implies that all reasonable models of computation are equivalent - that is,
they all decide the same class of languages. In complexity theory, the choice
of model affects the time complexity of languages. Languages that are decidable
in, say, linear time on one model aren&rsquo;t necessarily decidable in linear time
on another.&rdquo;</p>

<p>&ldquo;The same language may have different time requirements on different models.&rdquo;</p>

<p>&ldquo;We show that any language that is decidable on [a nondeterministic
single-tape machine] is decidable on a deterministic single-tape Turing
machine that requires significantly more time.&rdquo;</p>
</blockquote>

<p><b>
Thanks Sipser, when I&rsquo;m not being tested on the subject your book is really quite swell.
</b></p>

<p>So a NP problem only takes polynomial time on a nondeterministic Turing
machine, which has infinite parallelism. Think NFA that splits each time it
encounters multiple possible paths. Every NFA has an equivalent DFA; however,
when that NFA is converted to an equivalent DFA, the number of states may be
exponential in the number of states in the NFA.</p>

<blockquote>
<p>&ldquo;First, note the dramatic difference between the growth rate of a typically
occurring polynomials such as n<sup>3</sup> and typically occurring
exponentials such as 2<sup>n</sup>. For example, let n be 1000, the size of a
reasonable input to an algorithm. In that case, n<sup>3</sup> is 1 billion, a
large but manageable number, whereas 2<sup>n</sup> is a number much larger than
the number of atoms in the universe. Polynomial time algorithms are fast enough
for many purposes, but exponential time algorithms rarely are useful.&rdquo;</p>
</blockquote>

<p><a href="http://abstrusegoose.com/a/206.htm">http://abstrusegoose.com/a/206.htm</a>
<a href="http://www-math.mit.edu/~sipser/book.html">http://www-math.mit.edu/~sipser/book.html</a></p>

    </article>
  

  </body>
</html>
